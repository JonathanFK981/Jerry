{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:19:15.224500Z",
     "start_time": "2022-06-25T16:19:15.219847Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import os\n",
    "\n",
    "from ..dataloading import get_yolox_datadir\n",
    "from .datasets_wrapper import Dataset\n",
    "\n",
    "\n",
    "class MOTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    COCO dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir=None,\n",
    "        json_file=\"train_half.json\",\n",
    "        name=\"train\",\n",
    "        img_size=(608, 1088),\n",
    "        preproc=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        COCO dataset initialization. Annotation data are read into memory by COCO API.\n",
    "        Args:\n",
    "            data_dir (str): dataset root directory\n",
    "            json_file (str): COCO json file name\n",
    "            name (str): COCO data name (e.g. 'train2017' or 'val2017')\n",
    "            img_size (int): target image size after pre-processing\n",
    "            preproc: data augmentation strategy\n",
    "        \"\"\"\n",
    "        super().__init__(img_size)\n",
    "        if data_dir is None:\n",
    "            data_dir = os.path.join(get_yolox_datadir(), \"Jerry\")\n",
    "        self.data_dir = data_dir\n",
    "        self.json_file = json_file\n",
    "\n",
    "        self.coco = COCO(os.path.join(self.data_dir, \"annotations\", self.json_file))\n",
    "        self.ids = self.coco.getImgIds()\n",
    "        self.class_ids = sorted(self.coco.getCatIds())\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        self._classes = tuple([c[\"name\"] for c in cats])\n",
    "        self.annotations = self._load_coco_annotations()\n",
    "        self.name = name\n",
    "        self.img_size = img_size\n",
    "        self.preproc = preproc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def _load_coco_annotations(self):\n",
    "        return [self.load_anno_from_ids(_ids) for _ids in self.ids]\n",
    "\n",
    "    def load_anno_from_ids(self, id_):\n",
    "        im_ann = self.coco.loadImgs(id_)[0]\n",
    "        width = im_ann[\"width\"]\n",
    "        height = im_ann[\"height\"]\n",
    "        frame_id = im_ann[\"frame_id\"]\n",
    "        video_id = im_ann[\"video_id\"]\n",
    "        anno_ids = self.coco.getAnnIds(imgIds=[int(id_)], iscrowd=False)\n",
    "        annotations = self.coco.loadAnns(anno_ids)\n",
    "        objs = []\n",
    "        for obj in annotations:\n",
    "            x1 = obj[\"bbox\"][0]\n",
    "            y1 = obj[\"bbox\"][1]\n",
    "            x2 = x1 + obj[\"bbox\"][2]\n",
    "            y2 = y1 + obj[\"bbox\"][3]\n",
    "            if obj[\"area\"] > 0 and x2 >= x1 and y2 >= y1:\n",
    "                obj[\"clean_bbox\"] = [x1, y1, x2, y2]\n",
    "                objs.append(obj)\n",
    "\n",
    "        num_objs = len(objs)\n",
    "\n",
    "        res = np.zeros((num_objs, 6))\n",
    "\n",
    "        for ix, obj in enumerate(objs):\n",
    "            cls = self.class_ids.index(obj[\"category_id\"])\n",
    "            res[ix, 0:4] = obj[\"clean_bbox\"]\n",
    "            res[ix, 4] = cls\n",
    "            res[ix, 5] = obj[\"track_id\"]\n",
    "\n",
    "        file_name = im_ann[\"file_name\"] if \"file_name\" in im_ann else \"{:012}\".format(id_) + \".jpg\"\n",
    "        img_info = (height, width, frame_id, video_id, file_name)\n",
    "\n",
    "        del im_ann, annotations\n",
    "\n",
    "        return (res, img_info, file_name)\n",
    "\n",
    "    def load_anno(self, index):\n",
    "        return self.annotations[index][0]\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        id_ = self.ids[index]\n",
    "\n",
    "        res, img_info, file_name = self.annotations[index]\n",
    "        # load image and preprocess\n",
    "        img_file = os.path.join(\n",
    "            self.data_dir, self.name, file_name\n",
    "        )\n",
    "        img = cv2.imread(img_file)\n",
    "        assert img is not None\n",
    "\n",
    "        return img, res.copy(), img_info, np.array([id_])\n",
    "\n",
    "    @Dataset.resize_getitem\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        One image / label pair for the given index is picked up and pre-processed.\n",
    "\n",
    "        Args:\n",
    "            index (int): data index\n",
    "\n",
    "        Returns:\n",
    "            img (numpy.ndarray): pre-processed image\n",
    "            padded_labels (torch.Tensor): pre-processed label data.\n",
    "                The shape is :math:`[max_labels, 5]`.\n",
    "                each label consists of [class, xc, yc, w, h]:\n",
    "                    class (float): class index.\n",
    "                    xc, yc (float) : center of bbox whose values range from 0 to 1.\n",
    "                    w, h (float) : size of bbox whose values range from 0 to 1.\n",
    "            info_img : tuple of h, w, nh, nw, dx, dy.\n",
    "                h, w (int): original shape of the image\n",
    "                nh, nw (int): shape of the resized image without padding\n",
    "                dx, dy (int): pad size\n",
    "            img_id (int): same as the input index. Used for evaluation.\n",
    "        \"\"\"\n",
    "        img, target, img_info, img_id = self.pull_item(index)\n",
    "\n",
    "        if self.preproc is not None:\n",
    "            img, target = self.preproc(img, target, self.input_dim)\n",
    "        return img, target, img_info, img_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T16:46:36.311060Z",
     "start_time": "2022-06-25T16:46:35.694179Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374f172e1d998ab8261b7c22aef536e3aa294a69ab468e872b22f92cb32d0f1b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ByteTrack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
